# ğŸ“˜ Clasificator Articole Sportive (È˜tiri despre Becali vs Altele)

Acest proiect realizeazÄƒ automat:

1.  **Colectarea articolelor** (web scraping)\
2.  **Procesarea È™i etichetarea conÈ›inutului**\
3.  **Antrenarea unui model Naive Bayes** care clasificÄƒ articolele Ã®n:
    -   `Despre_Becali`\
    -   `Altele`

## Structura proiectului

    /proiect
    â”‚â”€â”€ colectare_date.py
    â”‚â”€â”€ procesare_date.py
    â”‚â”€â”€ model_bayes.py
    â”‚â”€â”€ articole_brute.csv        (generat automat)
    â”‚â”€â”€ articole_procesate.csv    (generat automat)


## 1. Colectarea datelor

**Script:** `colectare_date.py`\
**Output:** `articole_brute.csv`

Scraperul extrage articole de pe:

-   prosport.ro\
-   gsp.ro\
-   digisport.ro

Pentru fiecare articol se salveazÄƒ:

-   URL\
-   domeniu\
-   titlu\
-   conÈ›inut

### Rulare:

``` bash
python3 colectare_date.py
```

## 2. Procesarea È™i etichetarea datelor

**Script:** `procesare_date.py`\
**Input:** `articole_brute.csv`\
**Output:** `articole_procesate.csv`

OperaÈ›iile efectuate:

-   convertire la lowercase\
-   tokenizare\
-   eliminare stop-words romÃ¢neÈ™ti\
-   filtrare cuvinte scurte / non-alfabetice\
-   detecÈ›ie automatÄƒ a etichetei din titlu pe baza listelor:
    -   `ETICHETE_BECALI`
    -   `ETICHETE_ALTELE`

Articolele fÄƒrÄƒ cuvinte-cheie relevante sunt ignorate.

### Rulare:

``` bash
python3 procesare_date.py
```


## 3. Model Naive Bayes

**Script:** `model_bayes.py`\
**Input:** `articole_procesate.csv`

Ce face scriptul:

-   reconstruieÈ™te textul procesat\
-   vectorizeazÄƒ cu CountVectorizer\
-   Ã®mparte setul Ã®n train/test\
-   antreneazÄƒ modelul `MultinomialNB`\
-   afiÈ™eazÄƒ acurateÈ›ea\
-   oferÄƒ un prompt pentru testare manualÄƒ

### Rulare:

``` bash
python3 model_bayes.py
```

Exemplu testare:

    Scrie text pt test sau exit pt a inchide:
    > Becali a anunÈ›at...


## DependenÈ›e

InstaleazÄƒ pachetele necesare:

``` bash
pip install requests beautifulsoup4 pandas scikit-learn nltk unidecode
```

### Setup NLTK:

``` python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```
